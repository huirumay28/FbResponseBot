const express = require('express');
const multer = require('multer');
const XLSX = require('xlsx');
const puppeteer = require('puppeteer');
const cheerio = require('cheerio');
const path = require('path');
const fs = require('fs');
const { v4: uuidv4 } = require('uuid');

const router = express.Router();

// Configure multer for file uploads
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    const uploadDir = path.join(__dirname, '../../uploads');
    if (!fs.existsSync(uploadDir)) {
      fs.mkdirSync(uploadDir, { recursive: true });
    }
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const uniqueName = `${uuidv4()}-${file.originalname}`;
    cb(null, uniqueName);
  }
});

const upload = multer({
  storage: storage,
  fileFilter: (req, file, cb) => {
    const allowedTypes = [
      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
      'application/vnd.ms-excel'
    ];
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error('åªå…è¨±ä¸Šå‚³Excelæ–‡ä»¶ (.xlsx, .xls)'), false);
    }
  },
  limits: {
    fileSize: 5 * 1024 * 1024 // 5MB limit
  }
});

// Parse Excel response guide
const parseResponseGuide = (filePath) => {
  try {
    const workbook = XLSX.readFile(filePath);
    const sheetName = workbook.SheetNames[0];
    const worksheet = workbook.Sheets[sheetName];
    const data = XLSX.utils.sheet_to_json(worksheet);
    
    console.log('Excel raw data:', JSON.stringify(data.slice(0, 3), null, 2));
    console.log('Available columns:', Object.keys(data[0] || {}));
    
    // Expected format with new structure: é¡žåž‹, ç¯„ä¾‹, å›žè¦†ç¨®é¡ž, å›žè¦†ç¯„æœ¬
    const responseGuide = data.map((row, index) => {
      const item = {
        type: row['é¡žåž‹'] || row['Type'] || row['type'] || row['category'] || row['Category'],
        example: row['ç¯„ä¾‹'] || row['Example'] || row['example'] || row['sample'] || row['Sample'],
        replyType: row['å›žè¦†ç¨®é¡ž'] || row['Reply Type'] || row['replyType'] || row['response_type'] || row['ResponseType'],
        template: row['å›žè¦†ç¯„æœ¬'] || row['Reply Template'] || row['template'] || row['response'] || row['Response']
      };
      
      console.log(`Row ${index + 1}:`, item);
      
      // Check if all required fields are present
      const isValid = item.type && item.example && item.replyType && item.template;
      if (!isValid) {
        console.log(`Row ${index + 1} rejected - missing fields:`, {
          type: !!item.type,
          example: !!item.example,
          replyType: !!item.replyType,
          template: !!item.template
        });
      }
      
      return item;
    }).filter(item => item.type && item.example && item.replyType && item.template);
    
    console.log(`Total rows processed: ${data.length}, Valid rows: ${responseGuide.length}`);
    
    return responseGuide;
  } catch (error) {
    console.error('Excel parsing error:', error);
    throw new Error(`Excelè§£æžå¤±æ•—: ${error.message}`);
  }
};

// Scrape Facebook post comments
const scrapeFacebookComments = async (postUrls) => {
  let browser = null;
  try {
    browser = await puppeteer.launch({
      headless: true,
      args: ['--no-sandbox', '--disable-setuid-sandbox']
    });
    
    const page = await browser.newPage();
    await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36');
    
    const allComments = [];
    for (const url of postUrls) {
      try {
        console.log(`æ­£åœ¨çˆ¬å–: ${url}`);
        await page.goto(url, { waitUntil: 'networkidle2', timeout: 30000 });
        
        // Wait for comments to load
        await page.waitForTimeout(3000);
        
        // Try to expand comments by clicking "æŸ¥çœ‹æ›´å¤šç•™è¨€" or similar buttons
        try {
          await page.click('[data-testid="post-comments-expand-button"]');
          await page.waitForTimeout(2000);
        } catch (e) {
          // Button might not exist, continue
        }
        
        // Extract comments
        const comments = await page.evaluate(() => {
          const commentElements = document.querySelectorAll('[data-testid="comment"]');
          const comments = [];
          
          commentElements.forEach(element => {
            const authorElement = element.querySelector('[data-testid="comment-author"]');
            const textElement = element.querySelector('[data-testid="comment-text"]');
            
            if (authorElement && textElement) {
              comments.push({
                author: authorElement.textContent.trim(),
                text: textElement.textContent.trim(),
                timestamp: new Date().toISOString()
              });
            }
          });
          
          return comments;
        });
        
        allComments.push({
          postUrl: url,
          comments: comments
        });
        
      } catch (error) {
        console.error(`ç„¡æ³•çˆ¬å– ${url}: ${error.message}`);
        allComments.push({
          postUrl: url,
          comments: [],
          error: error.message
        });
      }
    }
    
    return allComments;
  } catch (error) {
    console.error('Facebook scraping error:', error);
    throw error;
  } finally {
    if (browser) {
      try {
        await browser.close();
      } catch (closeError) {
        console.error('Failed to close browser:', closeError);
      }
    }
  }
};

// Classify comment based on content analysis
const classifyComment = (commentText) => {
  // Don't use toLowerCase() for Chinese text - it doesn't work properly
  const text = commentText;
  
  // Category detection patterns
  const patterns = {
    'A': {
      keywords: ['ç¼ºè²¨', 'æ²’æœ‰', 'è³£å®Œ', 'æ²’ç¾è²¨', 'ä»€éº¼æ™‚å€™æœ‰', 'æœ‰è²¨å—Ž', 'é‚„æœ‰å—Ž', 'è²·ä¸åˆ°'],
      description: 'å•†å“è³£ä¸åˆ° / ç¼ºè²¨'
    },
    'B': {
      keywords: ['è¦æ ¼', 'å°ºå¯¸', 'é¡è‰²', 'å¤šå°‘éŒ¢', 'åƒ¹æ ¼', 'æ€Žéº¼è²·', 'åƒ¹ä½', 'æè³ª', 'æ€Žéº¼è¨‚'],
      description: 'å•†å“è¦æ ¼è©¢å•'
    },
    'C': {
      keywords: ['æ´»å‹•', 'æ€Žéº¼åƒåŠ ', 'è§£æ³•', 'æ–¹æ³•', 'å¦‚ä½•', 'è¦å‰‡', 'æŠ½çŽ', 'åƒåŠ '],
      description: 'æ´»å‹•åƒåŠ  / è§£æ³•è©¢å•'
    },
    'D': {
      keywords: ['è®š', 'å¥½æ£’', 'åŽ²å®³', 'å–œæ­¡', 'å¤ªæ£’äº†', 'æ”¯æŒ', 'åŠ æ²¹', 'ðŸ‘', 'â¤ï¸', 'ðŸ”¥'],
      description: 'ç¨±è®š / äº’å‹•'
    },
    'E': {
      keywords: ['çˆ›', 'å·®', 'ä¸å¥½', 'ç³Ÿç³•', 'é¨™äºº', 'åžƒåœ¾', 'é›£ç”¨', 'å¾Œæ‚”', 'é€€è²¨', 'ä¸æŽ¨è–¦'],
      description: 'è² é¢è©•è«– / æŠ±æ€¨'
    },
    'F': {
      keywords: ['å¹¹', 'æ“', 'é ', 'ç™½ç™¡', 'æ™ºéšœ', 'æ­»', 'æ»¾', 'ä½Žèƒ½', 'ç™½ç—´', 'æ··è›‹'],
      description: 'æ”»æ“Š / é»‘äºº / ä¸é›…è©žå½™'
    },
    'G': {
      keywords: ['@', 'æ¨™è¨˜', 'æœ‹å‹', 'çœ‹çœ‹', 'å“ˆå“ˆ', 'ç¬‘æ­»', 'ðŸ˜‚', 'ðŸ¤£', 'ðŸ˜­'],
      description: 'Tag æœ‹å‹ / èªè­˜ / é–‹çŽ©ç¬‘'
    },
    'H': {
      keywords: ['ðŸ˜', 'ðŸ˜˜', 'ðŸ¥°', 'ðŸ˜Š', 'ðŸ˜„', 'ðŸ˜†', 'ðŸ¤”', 'ðŸ˜´', 'ðŸ™„'],
      description: 'ç„¡æ„ç¾©ç•™è¨€ / è¡¨æƒ…ç¬¦è™Ÿ / è²¼åœ–'
    },
    'I': {
      keywords: ['line', 'http', 'www', '.com', 'ig', 'facebook', 'fb', 'é€£çµ', 'åŠ line'],
      description: 'å»£å‘Š / Spam / é€£çµ'
    },
    'J': {
      keywords: ['hello', 'thank', 'good', 'nice', 'love', 'great', 'awesome', 'amazing'],
      description: 'è‹±æ–‡ / éžä¸­æ–‡ç•™è¨€'
    }
  };
  
  // Check for English content (non-Chinese characters)
  const chineseRegex = /[\u4e00-\u9fff]/;
  const englishRegex = /[a-zA-Z]/;
  if (englishRegex.test(text) && !chineseRegex.test(text)) {
    return 'J';
  }
  
  // Check for emoji-only content
  const emojiRegex = /^[\s\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}\u{1F680}-\u{1F6FF}\u{1F1E0}-\u{1F1FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]+$/u;
  if (emojiRegex.test(text)) {
    return 'H';
  }
  
  // Check for @ mentions
  if (text.includes('@')) {
    return 'G';
  }
  
  // Check other patterns
  for (const [category, pattern] of Object.entries(patterns)) {
    if (pattern.keywords.some(keyword => text.includes(keyword))) {
      return category;
    }
  }
  
  return 'H'; // Default to meaningless comment
};

// Generate responses based on response guide
const generateResponses = (comments, responseGuide) => {
  const processedComments = [];
  
  comments.forEach(postData => {
    postData.comments.forEach(comment => {
      // Classify the comment
      const category = classifyComment(comment.text);
      
      // Find matching response guide for this category
      const matchingGuide = responseGuide.find(guide => 
        guide.type === category || guide.type.includes(category)
      );
      
      let suggestedResponse = 'ç„¡åŒ¹é…å›žè¦†';
      let replyType = 'ä¸å›žè¦†';
      
      if (matchingGuide) {
        suggestedResponse = matchingGuide.template;
        replyType = matchingGuide.replyType;
      }
      
      processedComments.push({
        è²¼æ–‡é€£çµ: postData.postUrl,
        ç•™è¨€è€…: comment.author,
        ç•™è¨€å…§å®¹: comment.text,
        æ™‚é–“: comment.timestamp,
        åˆ†é¡ž: category,
        å›žè¦†ç¨®é¡ž: replyType,
        å»ºè­°å›žè¦†: suggestedResponse
      });
    });
  });
  
  return processedComments;
};

// API Endpoints

// Upload and parse response guide
router.post('/upload-guide', upload.single('responseGuide'), (req, res) => {
  let filePath = null;
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'è«‹ä¸Šå‚³Excelæ–‡ä»¶' });
    }
    
    filePath = req.file.path;
    const responseGuide = parseResponseGuide(filePath);
    
    // Clean up uploaded file
    fs.unlinkSync(filePath);
    
    res.json({
      success: true,
      message: 'å›žè¦†æº–å‰‡ä¸Šå‚³æˆåŠŸ',
      data: responseGuide
    });
  } catch (error) {
    // Clean up file even if error occurs
    if (filePath && fs.existsSync(filePath)) {
      try {
        fs.unlinkSync(filePath);
      } catch (cleanupError) {
        console.error('Failed to cleanup file:', cleanupError);
      }
    }
    res.status(400).json({ error: error.message });
  }
});

// Process posts and generate responses
router.post('/process-posts', async (req, res) => {
  try {
    const { postUrls, responseGuide } = req.body;
    
    if (!postUrls || !Array.isArray(postUrls) || postUrls.length === 0) {
      return res.status(400).json({ error: 'è«‹æä¾›æœ‰æ•ˆçš„è²¼æ–‡é€£çµ' });
    }
    
    if (!responseGuide || !Array.isArray(responseGuide) || responseGuide.length === 0) {
      return res.status(400).json({ error: 'è«‹æä¾›æœ‰æ•ˆçš„å›žè¦†æº–å‰‡' });
    }
    
    // Scrape comments
    const scrapedData = await scrapeFacebookComments(postUrls);
    
    // Generate responses
    const processedComments = generateResponses(scrapedData, responseGuide);
    
    // Create Excel file
    const worksheet = XLSX.utils.json_to_sheet(processedComments);
    const workbook = XLSX.utils.book_new();
    XLSX.utils.book_append_sheet(workbook, worksheet, 'ç•™è¨€å›žè¦†');
    
    // Save to temporary file
    const outputDir = path.join(__dirname, '../../output');
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }
    
    const fileName = `facebook-responses-${Date.now()}.xlsx`;
    const filePath = path.join(outputDir, fileName);
    XLSX.writeFile(workbook, filePath);
    
    res.json({
      success: true,
      message: 'è™•ç†å®Œæˆ',
      data: {
        totalComments: processedComments.length,
        fileName: fileName,
        downloadUrl: `/api/bot/download/${fileName}`
      }
    });
    
  } catch (error) {
    console.error('è™•ç†è²¼æ–‡æ™‚å‡ºéŒ¯:', error);
    res.status(500).json({ error: error.message });
  }
});

// Download generated Excel file
router.get('/download/:fileName', (req, res) => {
  const fileName = req.params.fileName;
  
  // Security: Prevent path traversal attacks
  if (fileName.includes('..') || fileName.includes('/') || fileName.includes('\\')) {
    return res.status(400).json({ error: 'ç„¡æ•ˆçš„æ–‡ä»¶åç¨±' });
  }
  
  // Security: Only allow Excel files
  if (!fileName.match(/^facebook-responses-\d+\.xlsx$/)) {
    return res.status(400).json({ error: 'ç„¡æ•ˆçš„æ–‡ä»¶åç¨±æ ¼å¼' });
  }
  
  const filePath = path.join(__dirname, '../../output', fileName);
  
  if (!fs.existsSync(filePath)) {
    return res.status(404).json({ error: 'æ–‡ä»¶ä¸å­˜åœ¨' });
  }
  
  res.download(filePath, fileName, (err) => {
    if (err) {
      console.error('ä¸‹è¼‰éŒ¯èª¤:', err);
      res.status(500).json({ error: 'ä¸‹è¼‰å¤±æ•—' });
    }
  });
});

module.exports = router; 